{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMgEPm0iCEHhcraEG1rbz9X"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vC4ovl9p4cQk"},"outputs":[],"source":["import numpy as np\n","import nltk\n","import string\n","import random"]},{"cell_type":"code","source":["f=open('/content/chatbot.txt','r',errors = 'ignore')\n","raw_doc=f.read()\n","raw_doc=raw_doc.lower()\n","nltk.download('punkt')\n","nltk.download('wordnet')\n","sent_tokens=nltk.sent_tokenize(raw_doc)\n","word_tokens=nltk.word_tokenize(raw_doc)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tuwiVpi34tGI","executionInfo":{"status":"ok","timestamp":1722773244361,"user_tz":-330,"elapsed":727,"user":{"displayName":"Arul Angelin","userId":"14884310012048570338"}},"outputId":"b439faa1-7112-4293-9f96-d681181f1b31"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]}]},{"cell_type":"code","source":["word_tokens[:2]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ycMRJpxR-FAs","executionInfo":{"status":"ok","timestamp":1722773251646,"user_tz":-330,"elapsed":703,"user":{"displayName":"Arul Angelin","userId":"14884310012048570338"}},"outputId":"eb119678-99db-41a2-89e5-2ad8e1f20b9e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['``', 'ai']"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["sent_tokens[:2]"],"metadata":{"id":"yc84f4QShXwY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["lemmer=nltk.stem.WordNetLemmatizer()\n","def LemTokens(tokens):\n","  return [lemmer.lemmatize(token) for token in tokens]\n","remove_punct_dict=dict((ord(punct), None) for punct in string.punctuation)\n","def LemNormalize(text):\n","  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"],"metadata":{"id":"Mv8XMDr2-V4H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["GREET_INPUTS = (\"hello\",\"hi\",\"greetings\",\"sup\",\"what's up\",\"hey\")\n","GREET_RESPONSES = [\"hi\",\"hey\",\"*nods*\",\"hi there\",\"hello\",\"I am glad! You are talking to me\"]\n","def greet(sentence):\n","  for word in sentence.split():\n","    if word.lower() in GREET_INPUTS:\n","      return random.choice(GREET_RESPONSES)"],"metadata":{"id":"TrjzEIb1_wUW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.metrics.pairwise import cosine_similarity"],"metadata":{"id":"FUhomp0kBA2G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def response(user_response):\n","  robol_response=''\n","  TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n","  tfidf=TfidfVec.fit_transform(sent_tokens)\n","  vals=cosine_similarity(tfidf[-1],tfidf)\n","  idx=vals.argsort()[0][-2]\n","  flat=vals.flatten()\n","  flat.sort()\n","  req_tfidf=flat[-2]\n","  if(req_tfidf==0):\n","    robol_response=robol_response+\"I am sorry! I don't understand you\"\n","    return robol_response\n","  else:\n","      robol_response=robol_response+sent_tokens[idx]\n","      return robol_response"],"metadata":{"id":"-NaTkKX4BoSR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["flag=True\n","print(\"BOT: My name is Angel. Let's have a conversation! Also, if you want to exit any time, just type Bye!\")\n","while(flag==True):\n","  user_response=input()\n","  user_response=user_response.lower()\n","  if(user_response!='bye'):\n","    if(user_response=='thanks' or user_response=='thank you'):\n","      flag=False\n","      print(\"BOT: You are welcome..\")\n","    else:\n","      if (greet(user_response)!=None):\n","        print(\"BOT: \"+greet(user_response))\n","      else:\n","        sent_tokens.append(user_response)\n","        word_tokens=word_tokens+nltk.word_tokenize(user_response)\n","        final_words=list(set(word_tokens))\n","        print(\"BOT: \",end=\"\")\n","        print(response(user_response))\n","        sent_tokens.remove(user_response)\n","  else:\n","    flag=False\n","    print(\"BOT: Goodbye! Take care <3\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ELGmSHm2EE-k","executionInfo":{"status":"ok","timestamp":1722773321430,"user_tz":-330,"elapsed":53206,"user":{"displayName":"Arul Angelin","userId":"14884310012048570338"}},"outputId":"2cfca319-4e3f-48f5-cb8d-6327eeadd799"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["BOT: My name is Angel. Let's have a conversation! Also, if you want to exit any time, just type Bye!\n","hi\n","BOT: hi there\n","hello\n","BOT: hello\n","sup\n","BOT: *nods*\n","Artificial Intelligence\n","BOT: part of a series on\n","artificial intelligence\n","\n","major goals\n","approaches\n","applications\n","philosophy\n","history\n","glossary\n","vte\n","artificial intelligence (ai), in its broadest sense, is intelligence exhibited by machines, particularly computer systems.\n","Future\n","BOT: critics argue that these questions may have to be revisited by future generations of ai researchers.\n","Foundation\n","BOT: [o][230] the methodology of speculating about future employment levels has been criticised as lacking evidential foundation, and for implying that technology, rather than social policy, creates unemployment, as opposed to redundancies.\n","Bye\n","BOT: Goodbye! Take care <3\n"]}]}]}